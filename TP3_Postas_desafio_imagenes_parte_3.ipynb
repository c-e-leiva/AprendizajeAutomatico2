{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/c-e-leiva/AprendizajeAutomatico2/blob/main/TP3_Postas_desafio_imagenes_parte_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **‚öôÔ∏è Configuraci√≥n del entorno: Activaci√≥n de GPU**\n",
        "\n",
        "Para acelerar el entrenamiento del modelo, se habilit√≥ el uso de GPU en el entorno de ejecuci√≥n. Esto permite procesar grandes vol√∫menes de datos de forma mucho m√°s eficiente, especialmente √∫til en tareas de aprendizaje profundo.\n",
        "\n",
        "#### ‚úÖ C√≥mo activar la GPU en Google Colab:\n",
        "\n",
        "1. Ir al men√∫ superior: `Entorno de ejecuci√≥n` ‚Üí `Cambiar tipo de entorno de ejecuci√≥n`.\n",
        "2. En el apartado `Acelerador de hardware`, seleccionar `GPU`.\n",
        "3. Presionar `Guardar`.\n",
        "\n",
        "Una vez hecho esto, se puede verificar si la GPU est√° activa y detectar su nombre con el siguiente c√≥digo en PyTorch:\n"
      ],
      "metadata": {
        "id": "HPz5cJDPH4aT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(\"‚úÖ GPU activa:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"‚ùå GPU no disponible\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBA6V2isFiic",
        "outputId": "1377d598-a09a-400e-9189-17ae9adc9039"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ GPU activa: ‚ùå GPU no disponible\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zh5mswsF7dJg"
      },
      "source": [
        "# **Clasificaci√≥n de Im√°genes con PyTorch y redes convolucionales**\n",
        "\n",
        "**TRABAJO EN EQUIPO POR POSTAS**\n",
        "\n",
        "#**POSTA 1: NORBERTO MARTEARENA URQUIZA - PASO 1**\n",
        "\n",
        "#**POSTA 2: MARCOS GALLO - PASO 2**\n",
        "\n",
        "#**POSTA 3: CARLOS EZEQUIEL LEIVA - PASO 3**\n",
        "\n",
        ".\n",
        "\n",
        ".\n",
        "\n",
        "\n",
        "\n",
        "## Objetivos\n",
        "\n",
        "Este trabajo pr√°ctico tiene como objetivo evaluar su capacidad para:\n",
        "- Implementar un data loader personalizado en PyTorch\n",
        "- Dise√±ar e implementar redes neuronales convolucionales\n",
        "- Entrenar y evaluar modelos de aprendizaje profundo\n",
        "- Documentar adecuadamente el proceso y resultados de cada consigna.\n",
        "\n",
        "## Parte 1: Clasificador de Perros y Gatos con CNN\n",
        "\n",
        "### Datos\n",
        "He utilizado el dataset \"Cats and Dogs\" de Microsoft disponible en el sitio oficial, para ello utilice el generador de colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqZNRrYQseof"
      },
      "source": [
        "BREVE INTRODUCCI√ìN a mi Posta (Posta 1)\n",
        "\n",
        "En este primer paso del trabajo pr√°ctico me enfoque en preparar y explorar el dataset que ser√° utilizado para entrenar una red neuronal convolucional (CNN). El objetivo es dejar listo un conjunto de datos limpio, balanceado, transformado y estructurado en DataLoaders que puedan ser utilizados por el resto del equipo en las siguientes etapas.\n",
        "\n",
        "Para ello:\n",
        "- Se implement√≥ un dataset personalizado basado en `torch.utils.data.Dataset`.\n",
        "- Se incorporaron transformaciones b√°sicas (normalizaci√≥n, redimensionamiento, data augmentation).\n",
        "- Se parametrizaron variables para facilitar pruebas con distintos tama√±os de imagen o subconjuntos de datos.\n",
        "- Se dividi√≥ el dataset en entrenamiento, validaci√≥n y prueba (70/15/15).\n",
        "- Se realiz√≥ una exploraci√≥n inicial visual y cuantitativa para verificar la correcta distribuci√≥n de clases y el formato de los tensores.\n",
        "\n",
        "Este trabajo est√° pensado para facilitar el trabajo en equipo y permitir ajustes simples mediante la modificaci√≥n de variables globales sin tocar el cuerpo principal del c√≥digo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Utu8TEs_-Vki"
      },
      "source": [
        "#**PASO 1 - POSTA 1. Preprocesamiento y Data Loader. [Nombre de quien resuelve: Norberto Martearena Urquiza]**\n",
        "\n",
        "-1.1 Descargue y descomprima el dataset.\n",
        "\n",
        "-1.2 Implemente su propio data loader personalizado utilizando las clases Dataset y DataLoader de PyTorch.\n",
        "\n",
        "-1.2.1 Incluya transformaciones apropiadas para las im√°genes (redimensionamiento, normalizaci√≥n, data augmentation, etc.)\n",
        "\n",
        "-1.2.2 Divida los datos en conjuntos de entrenamiento, validaci√≥n y prueba (sugerencia: 70%, 15%, 15%).\n",
        "\n",
        "-1.3 Realice una exploraci√≥n inicial de los datos (distribuci√≥n de clases, dimensiones de las im√°genes, etc.)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6YJIwAwCALT"
      },
      "source": [
        "#PASO 1.1 DESCARGA DEL archivo del sitio oficial kagglecatsanddogs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTE7qcUfqbmD"
      },
      "source": [
        "En esta secci√≥n descargamos y descomprimimos el dataset original completo desde el sitio oficial de Microsoft. La descarga y extracci√≥n se realiza con los comandos `wget` y `unzip`, respectivamente, generados por la opcion de colab.\n",
        "\n",
        "‚ùó Importante:\n",
        "Ni `wget` ni `unzip` permiten limitar directamente la cantidad de archivos (IMAGENES) que se descargan o descomprimen. Siempre se descarga y extrae el paquete completo.\n",
        "\n",
        "‚úÖ Para trabajar con un subconjunto de im√°genes (por ejemplo, 1000 gatos y 1000 perros), esta limitaci√≥n debe aplicarse luego en el c√≥digo Python, dentro del Dataset personalizado, mediante el par√°metro `max_per_class`.\n",
        "\n",
        "‚úÖ Para esta corrida, se asume el valor None, o sea, el valor por omision se le da el total de registros que trae originalmente, aunque este se puede modificar. Esta parametrizacion, se realizo en el PASO 1.2.1\n",
        "\n",
        "\n",
        "Esto permite controlar la cantidad de im√°genes utilizadas **sin modificar el archivo comprimido original**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mj1Na-mj9_49",
        "outputId": "1fe840c4-fccb-4f90-9595-0e01578a4a4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-06-02 20:23:07--  https://download.microsoft.com/download/3/e/1/3e1c3f21-ecdb-4869-8368-6deba77b919f/kagglecatsanddogs_5340.zip\n",
            "Resolving download.microsoft.com (download.microsoft.com)... 23.3.94.53, 2600:1408:c400:168a::317f, 2600:1408:c400:1680::317f\n",
            "Connecting to download.microsoft.com (download.microsoft.com)|23.3.94.53|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 824887076 (787M) [application/octet-stream]\n",
            "Saving to: ‚Äòkagglecatsanddogs_5340.zip.1‚Äô\n",
            "\n",
            "kagglecatsanddogs_5 100%[===================>] 786.67M  68.8MB/s    in 12s     \n",
            "\n",
            "2025-06-02 20:23:20 (63.4 MB/s) - ‚Äòkagglecatsanddogs_5340.zip.1‚Äô saved [824887076/824887076]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# prompt: descargar https://download.microsoft.com/download/3/e/1/3e1c3f21-ecdb-4869-8368-6deba77b919f/kagglecatsanddogs_5340.zip\n",
        "\n",
        "!wget https://download.microsoft.com/download/3/e/1/3e1c3f21-ecdb-4869-8368-6deba77b919f/kagglecatsanddogs_5340.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7zdGVeb_kOY"
      },
      "source": [
        "##PASO 1.1.1 DESCOMPRIMIR EL ARCHIVO\n",
        "\n",
        "REALIZO LA DESCOMPRESION DEL ARCHIVO BAJADO UTILIZANDO LAS NUEVAS FACILIDADES DE COLAB PARA LA GENERACION DE CODIGO  IGUAL QUE EN LA DESCARGA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zMcnFL49_yvk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "630f69f3-1e6d-45aa-96c1-75992abc7478"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "replace PetImages/Cat/0.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "\n",
        "# prompt: DESCOMPRIMO EL ARCHIVO ZIP BAJADO\n",
        "\n",
        "!unzip -q kagglecatsanddogs_5340.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5smbnQPsSsZC"
      },
      "source": [
        "q significa quiet (modo silencioso): evita mostrar en pantalla todos los archivos que est√° extrayendo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAOLHXc5TCa3"
      },
      "source": [
        "El archivo kagglecatsanddogs_5340.zip contiene una carpeta llamada PetImages/, con dos subcarpetas:\n",
        "\n",
        "PetImages/Cat/\n",
        "\n",
        "PetImages/Dog/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KymQE_PAU0DN"
      },
      "source": [
        "con el siguiente comando se muestran los archivos y carpetas en el directorio actual con detalles como tama√±o, permisos, fecha y nombre.\n",
        "en este caso especifico -1, permite verificar visualmente que el archivo fue descomprimido correctamente y que la carpeta PetImages/ est√° disponible."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uG7EU9EjArEH"
      },
      "outputs": [],
      "source": [
        "! ls -l"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uN2J3GxvBFay"
      },
      "outputs": [],
      "source": [
        "! ls -l PetImages/Dog/*.jpg | wc -l"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12zXhjcvVnt6"
      },
      "source": [
        "wc -1, es para confirmar que hay efectivamente 12.500 im√°genes de perros (o las que quedaron tras la descompresi√≥n), y se puede verificar que tiene la misma cantidad la carpeta de gatos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXyqyiLsEWgs"
      },
      "source": [
        "*En esta tarea voy a cargar solo los nombres de los archivos .jpg, de la carpeta /Dog y de la carpeta /Cat, para que no me tome otros archivos que existan que no sean .jpg, como por ejemplo .DB*\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LZNSxzz4eKdF"
      },
      "outputs": [],
      "source": [
        "# prompt: cargar los nombres de archivos del directorio PetImages que sean jpg\n",
        "# aqui  Versi√≥n optimizada para listar archivos v√°lidos por clase\n",
        "import os\n",
        "\n",
        "cat_files = [f for f in os.listdir('PetImages/Cat') if f.endswith('.jpg')]\n",
        "dog_files = [f for f in os.listdir('PetImages/Dog') if f.endswith('.jpg')]\n",
        "\n",
        "print(f\"Total im√°genes .jpg en Cat: {len(cat_files)}\")\n",
        "print(f\"Total im√°genes .jpg en Dog: {len(dog_files)}\")\n",
        "\n",
        "# Visualizaci√≥n de los primeros 10 archivos de cada clase\n",
        "print(\"Ejemplos Cat:\", cat_files[:10])\n",
        "print(\"Ejemplos Dog:\", dog_files[:10])\n",
        "\n",
        "\n",
        "# Este paso permite verificar si hay nombres inusuales, errores de codificaci√≥n o archivos duplicados y se indica la cantidad de imagenes en cada sub carpeta\n",
        "# Tambi√©n ayuda a observar patrones como si hay im√°genes con nombres como `0.jpg`, etc. Esto ser√° √∫til al momento de cargarlos como datos etiquetados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "m2EHrU8cK_fv"
      },
      "outputs": [],
      "source": [
        "dog_files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXeKWWlBOcfo"
      },
      "source": [
        "#**PASO 1.2**\n",
        "\n",
        "Implemente su propio data loader personalizado utilizando las clases Dataset y DataLoader de PyTorch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNlcKtm-QUsn"
      },
      "source": [
        "#**PASO 1.2 - Dataset personalizado**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zRIYB96GpVeH"
      },
      "outputs": [],
      "source": [
        "# PASO 1.2 - Dataset personalizado\n",
        "# prompt: Crear una clase Dataset que cargue im√°genes desde carpetas Cat y Dog con etiquetas autom√°ticas y control de errores.\n",
        "# ----------------------------- Importar librerias\n",
        "import os\n",
        "from PIL import Image, UnidentifiedImageError\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import torchvision.transforms as transforms\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5O5AdsUqfkUn"
      },
      "source": [
        "En esta secci√≥n definimos una clase Dataset personalizada llamada GatosPerrosDataset que permite:\n",
        "\n",
        "cargar im√°genes desde las carpetas PetImages/Cat y PetImages/Dog\n",
        "\n",
        "Asignar autom√°ticamente etiquetas 0 a los gatos y 1 a los perros seg√∫n el nombre de la carpeta\n",
        "\n",
        "Aplicar transformaciones a las im√°genes (rescale, normalizaci√≥n, etc.)\n",
        "\n",
        "Manejar errores por im√°genes corruptas usando try/except\n",
        "\n",
        "Esta clase es una subclase de torch.utils.data.Dataset y es fundamental para usar DataLoader luego.\n",
        "\n",
        "   \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dRg8-N5sprgv"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Creamos una clase heredada de torch.utils.data.Dataset\n",
        "# que permite cargar im√°genes desde carpetas \"PetImages/Cat\" y \"PetImages/Dog\".\n",
        "# Se asignan etiquetas autom√°ticas (0=gato, 1=perro) seg√∫n el nombre de la carpeta.\n",
        "#\n",
        "# ‚ö†Ô∏è Se agreg√≥ un bloque try/except en __getitem__ para evitar errores por im√°genes corruptas.\n",
        "# Si una imagen no se puede abrir, se elige aleatoriamente otra y se informa por consola.\n",
        "\n",
        "class GatosPerrosDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None, max_per_class=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.data = []\n",
        "        clases = os.listdir(root_dir)\n",
        "\n",
        "        for idx, clase in enumerate(clases):\n",
        "            clase_path = os.path.join(root_dir, clase)\n",
        "            if not os.path.isdir(clase_path):\n",
        "                continue\n",
        "\n",
        "            archivos = [f for f in os.listdir(clase_path) if f.endswith('.jpg')]\n",
        "            if max_per_class:\n",
        "                archivos = archivos[:max_per_class]\n",
        "\n",
        "            for archivo in archivos:\n",
        "                self.data.append((os.path.join(clase_path, archivo), idx))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "          # Intentamos abrir la imagen. Si falla, probamos con otra aleatoria.\n",
        "          while True:\n",
        "              img_path, label = self.data[idx]\n",
        "              try:\n",
        "                  image = Image.open(img_path).convert(\"RGB\")\n",
        "                  if self.transform:\n",
        "                      image = self.transform(image)\n",
        "                  return image, label\n",
        "              except (UnidentifiedImageError, OSError) as e:\n",
        "                  print(f\"‚ö†Ô∏è Imagen inv√°lida: {img_path} ‚Äî {e}\")\n",
        "                  idx = torch.randint(0, len(self.data), (1,)).item()\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EA9iyo64TVO0"
      },
      "source": [
        "#**PASO 1.2.1  Incluya transformaciones apropiadas para las im√°genes (redimensionamiento, normalizaci√≥n, data augmentation, etc.)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "co3irnzkrEW-"
      },
      "outputs": [],
      "source": [
        "# prompt: Definir par√°metros por defecto y transformaciones para preprocesar im√°genes de entrada al modelo.\n",
        "\n",
        "# -----------------------------\n",
        "# PASO 1.2.1 - Transformaciones y configuraciones por defecto\n",
        "# -----------------------------\n",
        "\n",
        "# Defino variables configurables para permitir ajustes sin cambiar el c√≥digo base\n",
        "image_size = 128              # Tama√±o de imagen a usar (por defecto: 128x128)\n",
        "batch_size = 32               # Tama√±o del lote de entrenamiento (modificable para pruebas de memoria o estabilidad)\n",
        "max_images_per_class = None   # Cantidad m√°xima de im√°genes por clase (None usa todas, por ejemplo las 12500 por clase)\n",
        "\n",
        "# Aplicamos transformaciones comunes para entrenamiento:\n",
        "# - Resize: redimensiona todas las im√°genes al tama√±o definido (image_size x image_size)\n",
        "# - RandomHorizontalFlip: voltea horizontalmente algunas im√°genes para aumentar variedad (data augmentation)\n",
        "# - ToTensor: convierte la imagen a tensor y normaliza a valores [0, 1]\n",
        "# - Normalize: normaliza los canales de color a [-1, 1] centrando en 0 para estabilizar el entrenamiento\n",
        "\n",
        "data_transforms = transforms.Compose([\n",
        "    transforms.Resize((image_size, image_size)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T2njHlj0YF77"
      },
      "outputs": [],
      "source": [
        "# prompt: Cargar el dataset completo aplicando la clase personalizada con transformaciones y configuraci√≥n definida.\n",
        "\n",
        "# -----------------------------\n",
        "# Cargar dataset completo\n",
        "# -----------------------------\n",
        "\n",
        "# El archivo ya se descargo y se descomprimi√≥ el ZIP en PetImages/ en el paso 1.1 y paso  1.1.1\n",
        "# Esta ruta puede adaptarse si el directorio cambia\n",
        "ruta_dataset = \"PetImages\"\n",
        "dataset = GatosPerrosDataset(root_dir=ruta_dataset, transform=data_transforms, max_per_class=max_images_per_class)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MjETT_GdbgX"
      },
      "source": [
        "#**PASO 1.2.2 - Dividir en entrenamiento, validaci√≥n y prueba (70/15/15)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vug1_R8jrVCt"
      },
      "outputs": [],
      "source": [
        "# prompt: Dividir el dataset en subconjuntos de entrenamiento, validaci√≥n y prueba utilizando random_split.\n",
        "# -----------------------------\n",
        "# PASO 1.2.2 - Dividir en entrenamiento, validaci√≥n y prueba (70/15/15)\n",
        "# -----------------------------\n",
        "\n",
        "# Usamos torch.utils.data.random_split para dividir el conjunto\n",
        "longitud = len(dataset)\n",
        "entrenamiento, validacion, prueba = random_split(dataset, [int(0.7*longitud), int(0.15*longitud), longitud - int(0.7*longitud) - int(0.15*longitud)])\n",
        "\n",
        "# Creamos los dataloaders que se usar√°n en el entrenamiento del modelo\n",
        "train_loader = DataLoader(entrenamiento, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(validacion, batch_size=batch_size)\n",
        "test_loader = DataLoader(prueba, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--EanK-keZf5"
      },
      "source": [
        "#**PASO 1.3 - Exploraci√≥n de los datos**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6W-HN6_3pMW3"
      },
      "outputs": [],
      "source": [
        "# prompt: Explorar visualmente y cuantitativamente la distribuci√≥n de clases y forma de los tensores en los dataloaders.\n",
        "# -----------------------------\n",
        "# PASO 1.3 - Exploraci√≥n de los datos\n",
        "# -----------------------------\n",
        "\n",
        "# Analizamos la distribuci√≥n de etiquetas (clases) en cada subconjunto\n",
        "labels_entrenamiento = [label for _, label in entrenamiento]\n",
        "labels_validacion = [label for _, label in validacion]\n",
        "labels_prueba = [label for _, label in prueba]\n",
        "\n",
        "print(\"Distribuci√≥n de clases:\")\n",
        "print(\"Entrenamiento:\", Counter(labels_entrenamiento))\n",
        "print(\"Validaci√≥n:\", Counter(labels_validacion))\n",
        "print(\"Prueba:\", Counter(labels_prueba))\n",
        "\n",
        "# Visualizamos las dimensiones de los tensores de imagen\n",
        "sample_imgs, _ = next(iter(train_loader))\n",
        "print(\"Forma del lote de entrenamiento:\", sample_imgs.shape)  # (batch_size, canales, alto, ancho)\n",
        "\n",
        "# Visualizamos un grupo de 10 im√°genes del conjunto de entrenamiento\n",
        "fig, axs = plt.subplots(2, 5, figsize=(12, 5))\n",
        "for i, ax in enumerate(axs.flat):\n",
        "    img = sample_imgs[i].permute(1, 2, 0) * 0.5 + 0.5  # desnormalizamos para visualizar\n",
        "    ax.imshow(img)\n",
        "    ax.axis('off')\n",
        "plt.suptitle(\"Ejemplos de im√°genes de entrenamiento\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFaDXDIViulH"
      },
      "source": [
        "Recomendaciones clave:\n",
        "\n",
        "Correr el notebook completo desde el principio para que la clase GatosPerrosDataset est√© definida.\n",
        "No cambiar el nombre ni la estructura de carpetas: PetImages/Cat y PetImages/Dog deben estar presentes.\n",
        "Puede usar los siguientes valores por defecto:\n",
        "image_size = 128\n",
        "batch_size = 32\n",
        "max_per_class = 1000\n",
        "Las transformaciones sugeridas son:\n",
        "transformaciones = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
        "])\n",
        "üõ°Ô∏è Consideraciones especiales:\n",
        "\n",
        "Las im√°genes inv√°lidas est√°n controladas mediante try/except, pero si aparece el mensaje ‚ö†Ô∏è Imagen inv√°lida, no significa que el c√≥digo fall√≥.\n",
        "Si se desea trabajar con menos datos, puede ajustarse max_per_class en el momento de instanciar el dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2doMruJIlre6"
      },
      "source": [
        "#**CONCLUSIONES**\n",
        "\n",
        "\n",
        "La implementaci√≥n desarrollada en esta primera posta garantiza una base s√≥lida para el entrenamiento de modelos de clasificaci√≥n binaria con redes neuronales.\n",
        "\n",
        "De acuerdo a lo consensuado con la profesora la estructura modular y parametrizada permite que cualquier integrante del equipo pueda trabajar con distintas cantidades de datos, aplicar nuevas transformaciones o ajustar los hiperpar√°metros sin alterar el funcionamiento del conjunto.\n",
        "\n",
        "En futuras etapas, se podr√° observar c√≥mo el preprocesamiento influye directamente en el desempe√±o de los modelos CNN y MLP, como se vio en experiencias previas con subconjuntos reducidos de 500 im√°genes por clase, donde se identificaron problemas de carga de clases. Esta versi√≥n mejora ese comportamiento mediante mayor control, limpieza y balanceo de datos.\n",
        "\n",
        "La configuraci√≥n flexible y el control visual implementado tambi√©n brindan herramientas valiosas para la detecci√≥n de errores tempranos y el diagn√≥stico de la calidad del dataset.\n",
        "\n",
        "Como podran ver durante la ejecucion se detectaron dos imagenes que daban error y suspendian el proceso, por ese motivo se incorporaron las mejoras que permitieron omitir esas imagenes para una corrida normal.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "1EqNh1yX36S8"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyVuaHu7TMi8"
      },
      "source": [
        "# **PASO 2 Arquitectura de la Red. [Resuelve: MARCOS GALLO]**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWQZ9jE0b3o8"
      },
      "source": [
        "# **Consigna de la posta 2:**\n",
        "\n",
        "- Dise√±e una red neuronal convolucional para la clasificaci√≥n binaria (perros vs gatos)\n",
        "- La arquitectura debe utilizar exclusivamente capas convolucionales y fully-connected\n",
        "- Implemente correctamente el forward pass de la red\n",
        "- Justifique las decisiones de dise√±o (n√∫mero de capas, filtros, activaciones, etc.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBeqK_BxPCF-"
      },
      "source": [
        "## üß† Arquitectura de la Red Neuronal Convolucional (CNN) para clasificaci√≥n de Perros vs Gatos\n",
        "\n",
        "Se crear√° una clase que implementa una arquitectura CNN, dise√±ada  para la tarea de clasificaci√≥n binaria de im√°genes de gatos y perros.\n",
        "\n",
        "Se busc√≥ un dise√±o para facilitar el trabajo en equipo, flexible que permite modificar par√°metros para experimentar con variantes.\n",
        "\n",
        "---\n",
        "\n",
        "### üîß Arquitectura General\n",
        "\n",
        "La clase GatosPerrosCNN hereda de nn.Module y organiza su estructura compuesta por tres bloques convolucionales, seguidos por dos capas totalmente conectadas. Cada bloque realiza:\n",
        "\n",
        "- Convoluci√≥n 2D (`Conv2D`)\n",
        "- Activaci√≥n no lineal (por defecto: `ReLU`)\n",
        "- Reducci√≥n espacial mediante `MaxPooling`\n",
        "\n",
        "La parte final densa incluye:\n",
        "\n",
        "- Aplanado del tensor de activaciones\n",
        "- Capa fully connected intermedia con activaci√≥n\n",
        "- Capa de salida con 1 sola neurona y activaci√≥n Sigmoid para clasificaci√≥n binaria (probabilidad entre 0 y 1)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGNZow6HPxop"
      },
      "source": [
        "## üîç Par√°metros configurables del modelo `GatosPerrosCNN`\n",
        "\n",
        "A continuaci√≥n, se detallan los par√°metros del constructor del modelo `GatosPerrosCNN`, con el objetivo de facilitar su comprensi√≥n, experimentaci√≥n y adaptaci√≥n por parte de todos los integrantes del equipo.  \n",
        "\n",
        "---\n",
        "\n",
        "### üìå Argumentos del constructor\n",
        "\n",
        "- **`num_filters: list[int]`**  \n",
        "  Lista que indica la cantidad de filtros en cada capa convolucional.  \n",
        "  Por ejemplo: `[16, 32, 64]` define 3 capas con 16, 32 y 64 filtros respectivamente.  \n",
        "  Esto permite una progresiva extracci√≥n de patrones: de bordes simples a formas m√°s complejas.\n",
        "\n",
        "---\n",
        "\n",
        "- **`fc_hidden_units: int`**  \n",
        "  N√∫mero de neuronas en la capa `fully connected` intermedia.  \n",
        "  Une la parte convolucional (extracci√≥n de caracter√≠sticas) con la salida binaria (gato o perro).  \n",
        "  Com√∫nmente se usan valores como 64, 128 o 256.\n",
        "\n",
        "---\n",
        "\n",
        "- **`input_shape: tuple[int]`**  \n",
        "  Tama√±o esperado de las im√°genes de entrada en el formato `(canales, alto, ancho)`, por ejemplo `(3, 128, 128)` para im√°genes RGB.  \n",
        "  Es fundamental para calcular autom√°ticamente el tama√±o de entrada a la capa `fully connected`.  \n",
        "  Aunque las im√°genes del dataset se redimensionen a 128x128 por defecto en el preprocesamiento hecho en la Posta 1 (tambien es flexible), incluir este par√°metro hace el c√≥digo m√°s robusto y adaptable.\n",
        "\n",
        "---\n",
        "\n",
        "- **`use_dropout: bool`**  \n",
        "  Si se establece en `True`, agrega una capa `Dropout` antes de la salida.  \n",
        "  Esto ayuda a **prevenir el sobreajuste** al desactivar aleatoriamente neuronas durante el entrenamiento.  \n",
        "  Es √∫til especialmente si se detecta un rendimiento pobre en validaci√≥n.\n",
        "\n",
        "---\n",
        "\n",
        "- **`activation: Callable`**  \n",
        "  Funci√≥n de activaci√≥n utilizada despu√©s de cada capa convolucional y `fully connected`.  \n",
        "  Por defecto se usa `ReLU` (`torch.nn.ReLU()`), por su eficiencia y buen rendimiento promedio.  \n",
        "  Tambi√©n se podr√≠an probar otras como:\n",
        "  - `LeakyReLU()`: evita que neuronas se ‚Äúapaguen‚Äù totalmente.\n",
        "  - `tanh` o `sigmoid`: menos comunes, pero √∫tiles en arquitecturas peque√±as o experimentales.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PROMPT:\n",
        "# \"Por favor, crea una clase en Python que defina una red neuronal convolucional para clasificaci√≥n binaria de im√°genes (gatos vs perros).\n",
        "#La red debe tener 3 capas convolucionales con filtros de tama√±o 16, 32 y 64.Cada capa convolucional debe estar seguida de una capa de max pooling.\n",
        "#Incluye una capa fully connected final con una salida de un valor entre 0 y 1 usando sigmoid. Incluye opciones para usar dropout y una funci√≥n de\n",
        "#activaci√≥n configurable, por ejemplo ReLU.La clase debe calcular autom√°ticamente el tama√±o de la entrada a las capas fully connected.\n",
        "#Define un m√©todo forward para pasar los datos a trav√©s de la red.\"\n",
        "\n",
        "\n",
        "# Importa librer√≠as necesarias\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class GatosPerrosCNN(nn.Module):\n",
        "    def __init__(self, num_filters=[16, 32, 64], fc_hidden_units=128, input_shape=(3, 128, 128),\n",
        "                 use_dropout=False, activation=F.relu):\n",
        "        super(GatosPerrosCNN, self).__init__()\n",
        "\n",
        "        self.activation = activation\n",
        "        self.use_dropout = use_dropout\n",
        "\n",
        "        # Capas convolucionales\n",
        "        self.conv1 = nn.Conv2d(in_channels=input_shape[0], out_channels=num_filters[0], kernel_size=3, padding=1)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(num_filters[0], num_filters[1], kernel_size=3, padding=1)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(num_filters[1], num_filters[2], kernel_size=3, padding=1)\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        # C√°lculo del tama√±o de entrada a FC\n",
        "        self._calculate_flatten_dim(input_shape)\n",
        "\n",
        "        # Capas fully-connected\n",
        "        self.fc1 = nn.Linear(self.flatten_dim, fc_hidden_units)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fc2 = nn.Linear(fc_hidden_units, 1)\n",
        "\n",
        "    def _calculate_flatten_dim(self, input_shape):\n",
        "        c, h, w = input_shape\n",
        "        dummy_input = torch.zeros(1, c, h, w)\n",
        "        x = self.pool3(self.activation(self.conv3(\n",
        "            self.pool2(self.activation(self.conv2(\n",
        "                self.pool1(self.activation(self.conv1(dummy_input)))\n",
        "            )))\n",
        "        )))\n",
        "        self.flatten_dim = x.view(1, -1).shape[1]\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool1(self.activation(self.conv1(x)))\n",
        "        x = self.pool2(self.activation(self.conv2(x)))\n",
        "        x = self.pool3(self.activation(self.conv3(x)))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.activation(self.fc1(x))\n",
        "        if self.use_dropout:\n",
        "            x = self.dropout(x)\n",
        "        x = torch.sigmoid(self.fc2(x))\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "y62gUndxBTXV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üîç C√°lculo autom√°tico del tama√±o de entrada a la capa fully connected\n",
        "\n",
        "\n",
        "\n",
        "De esta manera lo que se evita es tener errores cuando se cambia el tama√±o de entrada o se modifican las capas convolucionales. La caracter√≠stica principal es que **el modelo calcula autom√°ticamente el tama√±o del vector que ingresa a la capa fully connected intermedia (fc1)**. Para ello, se pasa un tensor \"dummy\" de ceros a trav√©s de todas las capas convolucionales y de pooling, sin necesidad de calcular manualmente la reducci√≥n de tama√±o producida por las capas de pooling.\n",
        "\n",
        "Por ejemplo:\n",
        "\n",
        "\n",
        "`dummy_input = torch.zeros(1, c, h, w)`  \n",
        "`x = ...` # pasar dummy_input por las capas convolucionales y pooling  \n",
        "`self.flatten_dim = x.view(1, -1).shape[1]`  "
      ],
      "metadata": {
        "id": "IcdUoLDmf8pH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " ### ‚è© Explicaci√≥n del m√©todo `forward`\n",
        "\n",
        "El m√©todo `forward` define c√≥mo los datos de entrada (`x`) pasan a trav√©s de la red neuronal en cada paso. Primero, la entrada se procesa en una secuencia de capas convolucionales: `conv1`, `conv2` y `conv3`. Despu√©s de cada convoluci√≥n, se aplica una funci√≥n de activaci√≥n (`self.activation`) para introducir no linealidad, seguida de una capa de pooling (`pool1`, `pool2`, `pool3`) que reduce las dimensiones espaciales de las im√°genes, ayudando a extraer caracter√≠sticas de diferentes niveles de abstracci√≥n.\n",
        "\n",
        "Luego, la salida de la √∫ltima capa de pooling se aplana con `x.view(x.size(0), -1)`, convirtiendo el tensor en un vector para que pueda ingresarse a las capas totalmente conectadas (`fc1` y `fc2`).\n",
        "\n",
        "Antes de la √∫ltima capa, se aplica nuevamente la funci√≥n de activaci√≥n, y, si `use_dropout` est√° habilitado, se activa.\n",
        "\n",
        "El par√°metro `use_dropout` controla si se debe aplicar **regularizaci√≥n** por medio de `Dropout`, una t√©cnica que reduce el sobreajuste al \"apagar\" aleatoriamente algunas neuronas durante el entrenamiento.\n",
        "\n",
        "Si `use_dropout=True`, el modelo aplicar√° una capa `Dropout(0.5)` justo despu√©s de la activaci√≥n de la capa fully connected intermedia. Esta opci√≥n es √∫til cuando el modelo memoriza el entrenamiento pero falla en generalizar bien en validaci√≥n.\n",
        "\n",
        "Finalmente, la salida pasa por la capa `fc2` y se aplica la funci√≥n `sigmoid` para producir una probabilidad de clasificaci√≥n binaria (perro vs gato).\n",
        "\n"
      ],
      "metadata": {
        "id": "i94UhPBSiq6n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Uso recomendado:***\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Esta clase permite ser f√°cilmente modificada para comparar variantes de arquitectura:\n",
        "  - Cambiar n√∫mero de capas o filtros\n",
        "  - Probar otras funciones de activaci√≥n\n",
        "  - A√±adir Dropout\n",
        "  - Ajustar el tama√±o de im√°genes de entrada\n",
        "\n"
      ],
      "metadata": {
        "id": "-8G6hpJQfM7z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üîç Verificaci√≥n inicial de la red: instanciaci√≥n y prueba con input ficticio.\n",
        "\n",
        "Antes de entrenar una red neuronal convolucional, es fundamental verificar que la arquitectura est√© correctamente implementada. Es lo que sigue en los siguientes pasos:"
      ],
      "metadata": {
        "id": "Nv8sdHpTBXTH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚úÖ 1. Instanciaci√≥n del modelo"
      ],
      "metadata": {
        "id": "J2Q4GYEpBkIz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = GatosPerrosCNN(input_shape=(3, 128, 128))\n",
        "print(model)\n"
      ],
      "metadata": {
        "id": "7s-JMf2VBjnm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Qu√≠ se crea una instancia de la clase GatosPerrosCNN, especificando que las im√°genes de entrada tienen 3 canales (RGB) y tama√±o 128√ó128 p√≠xeles.\n",
        "\n",
        "Este paso permite asegurarse de que los tama√±os de entrada y salida entre capas est√°n bien conectados. El `print(model)` muestra toda la arquitectura del modelo con sus capas, canales y dimensiones, lo que facilita la revisi√≥n en equipo o individual antes del entrenamiento."
      ],
      "metadata": {
        "id": "vLhdLwA1Braw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üß™ 2. Prueba con input \"dummy\" (aleatorio)"
      ],
      "metadata": {
        "id": "MLePBCX6BvnY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dummy_input = torch.randn(1, 3, 128, 128)\n",
        "output_dummy = model(dummy_input)\n",
        "print(output_dummy)\n"
      ],
      "metadata": {
        "id": "hhVP0ubn6oln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Primero se crea un tensor ficticio con forma (1, 3, 128, 128) (una imagen RGB de prueba). Luego se lo pasa por el modelo y se imprime la salida.\n",
        "\n",
        "Este paso verifica el forward pass completo: se comprueba que la red acepta correctamente la entrada y devuelve una salida coherente. Dado que se trata de un problema de clasificaci√≥n binaria, la salida debe ser un tensor de forma (1, 1) con valores entre 0 y 1 gracias a la activaci√≥n sigmoid en la √∫ltima capa.\n",
        "\n",
        "‚úÖ Esta prueba detecta errores comunes como dimensiones incompatibles o errores de tipo, y permite trabajar con seguridad en la siguiente etapa de entrenamiento."
      ],
      "metadata": {
        "id": "Zy1EEMduB5AX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üìä Visualizaci√≥n de una imagen dummy y su predicci√≥n"
      ],
      "metadata": {
        "id": "9bFC2e5yB81g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Prompt: \"Dame un ejemplo de c√≥digo para visualizar una imagen dummy y su predicci√≥n\"\n",
        "\n",
        "# Librerias necesarias\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Convertir imagen dummy a formato visualizable\n",
        "imagen = dummy_input[0].permute(1, 2, 0).detach().numpy()\n",
        "plt.imshow((imagen - imagen.min()) / (imagen.max() - imagen.min()))\n",
        "plt.title(f\"Predicci√≥n del modelo: {output_dummy.item():.4f}\")\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "q4cCOoC5CApA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Qu√© hace este paso?\n",
        "\n",
        "`dummy_input[0]`: extrae la primera imagen del batch.\n",
        "\n",
        "`.permute(1, 2, 0)`: cambia los ejes para que se vea correctamente al graficar (altura, ancho, canales).\n",
        "\n",
        "`.detach().numpy()`: lo transforma en un array de NumPy para poder visualizarlo.\n",
        "\n",
        "`(imagen - imagen.min()) / (imagen.max() - imagen.min())`: normaliza los valores al rango [0, 1].\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "üìå ¬øQu√© muestra el gr√°fico?\n",
        "\n",
        "Una imagen completamente aleatoria (no es una muestra real del dataset). En el t√≠tulo del gr√°fico se muestra la salida del modelo.Ejemplo: Predicci√≥n del modelo: \"valor entre 0 y 1\", lo cual puede interpretarse como la probabilidad de que la imagen sea de un perro (1) o un gato (0).\n",
        "\n",
        "üß© Esta verificaci√≥n cumple un rol clave como validaci√≥n estructural del modelo antes del entrenamiento. Aunque la predicci√≥n no tiene valor real a√∫n (porque el modelo no ha sido entrenado), asegura que:\n",
        "\n",
        "- La arquitectura es funcional.\n",
        "\n",
        "- El forward pass se ejecuta sin errores.\n",
        "\n",
        "- Las dimensiones de entrada y salida son correctas.\n",
        "\n",
        "- Se puede visualizar la salida de forma interpretable.\n",
        "\n",
        "Este tipo de pruebas se toma como una buena pr√°ctica antes de configurar los hiperpar√°metros y ejecutar el entrenamiento completo.\n",
        "\n"
      ],
      "metadata": {
        "id": "HfdlrqjeCL9H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Referencias utilizadas:***\n",
        "\n",
        "---\n",
        "- Prompt chatgpt\n",
        "\n",
        "a)   Por favor, crea una clase en Python que defina una red neuronal convolucional para clasificaci√≥n binaria de im√°genes (gatos vs perros).\n",
        "La red debe tener 3 capas convolucionales con filtros de tama√±o 16, 32 y 64.Cada capa convolucional debe estar seguida de una capa de max pooling.\n",
        "Incluye una capa fully connected final con una salida de un valor entre 0 y 1 usando sigmoid. Incluye opciones para usar dropout y una funci√≥n de\n",
        "activaci√≥n configurable, por ejemplo ReLU.La clase debe calcular autom√°ticamente el tama√±o de la entrada a las capas fully connected.\n",
        "Define un m√©todo forward para pasar los datos a trav√©s de la red.\"\n",
        "\n",
        "b)   Dime puntos a tener en cuenta para lograr una estructura de codigo modular y flexible para un proyecto en equipo con consignas por \"postas\".\n",
        "\n",
        "c)   Dame un ejemplo de c√≥digo para visualizar una imagen dummy y su predicci√≥n.\n",
        "\n",
        "- Bibliograf√≠a de la materia\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KWGhLr84QhX0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "__________________________\n",
        "\n",
        "___________________________"
      ],
      "metadata": {
        "id": "pSqI73v8vA37"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PASO 3 Entrenamiento. [Resuelve: CARLOS E. LEIVA]**\n",
        "\n",
        "- 3.1 Configure los hiperpar√°metros del entrenamiento (learning rate, batch size, n√∫mero de √©pocas, etc.)\n",
        "\n",
        "- 3.2 Seleccione una funci√≥n de p√©rdida y un optimizador adecuados\n",
        "\n",
        "- .3.3 Implemente el bucle de entrenamiento completo\n",
        "\n",
        "- 3.4 Registre las m√©tricas de entrenamiento y validaci√≥n por √©poca (precisi√≥n, recall, F1-score, etc.)\n",
        "\n",
        "- 3.5 Implemente early stopping basado en el rendimiento de validaci√≥n"
      ],
      "metadata": {
        "id": "38PZanTwvGT7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3.1. Configurar Hiperpar√°metros**\n",
        "En esta secci√≥n definimos los hiperpar√°metros fundamentales para el entrenamiento de la red neuronal. Estos par√°metros controlan aspectos clave del proceso de optimizaci√≥n y afectan directamente el desempe√±o del modelo:\n",
        "\n",
        "- **Tasa de aprendizaje (learning_rate):** Indica qu√© tan grande es el paso que da el optimizador en cada actualizaci√≥n de pesos. Un valor demasiado alto puede hacer que el entrenamiento no converja, mientras que uno muy bajo puede hacer que el entrenamiento sea muy lento.\n",
        "- **Tama√±o del batch (batch_size):** Define la cantidad de muestras que se procesan antes de actualizar los pesos del modelo. Un batch peque√±o puede hacer el entrenamiento m√°s ruidoso pero puede generalizar mejor, mientras que un batch grande aprovecha mejor la paralelizaci√≥n.\n",
        "- **N√∫mero de √©pocas (num_epochs):** Cantidad de veces que el modelo recorrer√° todo el dataset de entrenamiento. M√°s √©pocas pueden mejorar el aprendizaje, pero tambi√©n pueden provocar sobreajuste si es excesivo.\n",
        "\n",
        "Estos par√°metros se eligen con base en la experiencia, la capacidad del hardware y las caracter√≠sticas del dataset, y pueden ajustarse posteriormente para mejorar el rendimiento.\n"
      ],
      "metadata": {
        "id": "T3g896bEvJ9x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hiperpar√°metros\n",
        "learning_rate = 0.001\n",
        "batch_size = 32\n",
        "num_epochs = 10"
      ],
      "metadata": {
        "id": "hiX-pDc8vFnH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3.2. Seleccionar funci√≥n de p√©rdida y optimizador**\n",
        "\n",
        "En el Paso 2 definimos el modelo `GatosPerrosCNN`, que termina con una capa de salida con activaci√≥n **sigmoide** para obtener una probabilidad entre 0 y 1.\n",
        "\n",
        "Para entrenar un modelo de clasificaci√≥n binaria, es clave elegir la funci√≥n de p√©rdida adecuada seg√∫n la salida del modelo:\n",
        "\n",
        "- Si el modelo **ya aplica sigmoide** en la √∫ltima capa (como `GatosPerrosCNN` del Paso 2), se debe usar **`BCELoss`**, que espera probabilidades como entrada.\n",
        "\n",
        "- Si prefieres usar una funci√≥n de p√©rdida m√°s estable num√©ricamente, puedes optar por **`BCEWithLogitsLoss`**, pero en ese caso debes **eliminar la sigmoide en el modelo** y entregar directamente los logits sin transformar. Esta funci√≥n combina internamente la sigmoide y la p√©rdida.\n",
        "\n",
        "Como optimizador, utilizamos **Adam**, que ajusta el aprendizaje para cada par√°metro y suele ser eficiente para redes convolucionales.\n"
      ],
      "metadata": {
        "id": "TMQgBBbfvWPn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Modelo previamente definido: model = GatosPerrosCNN(...)\n",
        "model = GatosPerrosCNN()\n",
        "\n",
        "# Funci√≥n de p√©rdida para clasificaci√≥n binaria\n",
        "criterion = nn.BCELoss()  # o nn.BCEWithLogitsLoss() si la salida no pasa por sigmoid\n",
        "\n",
        "# Optimizador Adam\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "dVkP5IB_vZVJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3.4. Registro de m√©tricas de entrenamiento y validaci√≥n por √©poca**\n",
        "\n",
        "En este bloque de c√≥digo implementamos el ciclo completo de entrenamiento y validaci√≥n para cada √©poca, incluyendo el c√°lculo y registro de m√©tricas clave para evaluar el desempe√±o del modelo.\n",
        "\n",
        "### Detalles importantes:\n",
        "\n",
        "- **Fijamos una semilla para reproducibilidad** usando `set_seed()`, asegurando que los resultados sean consistentes entre ejecuciones.\n",
        "- **Configuramos el dispositivo** para aprovechar GPU si est√° disponible, acelerando el entrenamiento.\n",
        "- Durante el **entrenamiento** (`model.train()`):\n",
        "  - Recorremos los batches del conjunto de entrenamiento.\n",
        "  - Movemos datos y etiquetas al dispositivo.\n",
        "  - Reseteamos gradientes (`optimizer.zero_grad()`).\n",
        "  - Calculamos la salida del modelo y la p√©rdida.\n",
        "  - Retropropagamos el error (`loss.backward()`) y actualizamos los pesos (`optimizer.step()`).\n",
        "  - Acumulamos la p√©rdida total y guardamos las predicciones y etiquetas reales para calcular m√©tricas al final de la √©poca.\n",
        "- Calculamos las **m√©tricas de entrenamiento** al finalizar la √©poca:\n",
        "  - P√©rdida promedio\n",
        "  - Precisi√≥n (Precision)\n",
        "  - Sensibilidad o recall (Recall)\n",
        "  - F1-score, que combina precisi√≥n y recall en una sola medida balanceada.\n",
        "- Durante la **validaci√≥n** (`model.eval()`):\n",
        "  - Desactivamos el c√°lculo de gradientes con `torch.no_grad()` para ahorrar memoria y c√≥mputo.\n",
        "  - Repetimos un proceso similar al entrenamiento pero sin optimizaci√≥n, solo evaluaci√≥n.\n",
        "  - Calculamos las mismas m√©tricas para medir la capacidad del modelo en datos no vistos durante el entrenamiento.\n",
        "- Finalmente, imprimimos un resumen formateado con el tiempo transcurrido por √©poca y todas las m√©tricas calculadas.\n",
        "\n",
        "### M√©tricas clave:\n",
        "\n",
        "- **Precisi√≥n (Precision):** proporci√≥n de predicciones positivas correctas entre todas las predicciones positivas.\n",
        "- **Recall:** proporci√≥n de verdaderos positivos detectados entre todos los positivos reales.\n",
        "- **F1-score:** media arm√≥nica de precisi√≥n y recall, √∫til para datasets desbalanceados.\n",
        "\n",
        "Este registro por √©poca permite monitorear el aprendizaje del modelo y detectar posibles problemas como overfitting (cuando la validaci√≥n empeora mientras que el entrenamiento mejora).\n"
      ],
      "metadata": {
        "id": "9xMzCO9rvlKP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# --- Fijamos la semilla para reproducibilidad ---\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "# --- Configuraci√≥n del dispositivo ---\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# --- Loop principal de entrenamiento ---\n",
        "for epoch in range(num_epochs):\n",
        "    start_time = time.time()\n",
        "\n",
        "    # ===== ENTRENAMIENTO =====\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    train_preds = []\n",
        "    train_labels = []\n",
        "\n",
        "    # Iteramos sobre los batches del conjunto de entrenamiento\n",
        "    for inputs, labels in train_loader:\n",
        "        # Movemos los datos al dispositivo (GPU o CPU)\n",
        "        inputs, labels = inputs.to(device), labels.float().to(device)\n",
        "\n",
        "        optimizer.zero_grad()          # Reiniciamos los gradientes\n",
        "        outputs = model(inputs).squeeze()  # Forward pass\n",
        "        loss = criterion(outputs, labels)  # C√°lculo de la p√©rdida\n",
        "        loss.backward()               # Backpropagation\n",
        "        optimizer.step()              # Actualizamos los pesos\n",
        "\n",
        "        train_loss += loss.item() * inputs.size(0)  # Acumulamos la p√©rdida\n",
        "        preds = (outputs > 0.5).int()               # Predicciones binarias (umbral 0.5)\n",
        "        train_preds.extend(preds.cpu().numpy())\n",
        "        train_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    # M√©tricas de entrenamiento por √©poca\n",
        "    epoch_train_loss = train_loss / len(train_loader.dataset)\n",
        "    epoch_train_precision = precision_score(train_labels, train_preds)\n",
        "    epoch_train_recall = recall_score(train_labels, train_preds)\n",
        "    epoch_train_f1 = f1_score(train_labels, train_preds)\n",
        "\n",
        "    # ===== VALIDACI√ìN =====\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    val_preds = []\n",
        "    val_labels = []\n",
        "\n",
        "    with torch.no_grad():  # Desactivamos el c√°lculo de gradientes\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.float().to(device)\n",
        "            outputs = model(inputs).squeeze()\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            val_loss += loss.item() * inputs.size(0)\n",
        "            preds = (outputs > 0.5).int()\n",
        "            val_preds.extend(preds.cpu().numpy())\n",
        "            val_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    # M√©tricas de validaci√≥n por √©poca\n",
        "    epoch_val_loss = val_loss / len(val_loader.dataset)\n",
        "    epoch_val_precision = precision_score(val_labels, val_preds)\n",
        "    epoch_val_recall = recall_score(val_labels, val_preds)\n",
        "    epoch_val_f1 = f1_score(val_labels, val_preds)\n",
        "\n",
        "    end_time = time.time()\n",
        "    elapsed = end_time - start_time\n",
        "\n",
        "    # ===== PRINT FORMATEADO POR √âPOCA =====\n",
        "    print(f\"üß† Epoch {epoch+1}/{num_epochs} - ‚è±Ô∏è Tiempo: {elapsed:.2f}s\")\n",
        "    print(f\"   üîπ Train -> Loss: {epoch_train_loss:.2f}, Precision: {epoch_train_precision:.2f}, Recall: {epoch_train_recall:.2f}, F1: {epoch_train_f1:.2f}\")\n",
        "    print(f\"   üî∏ Valid -> Loss: {epoch_val_loss:.2f}, Precision: {epoch_val_precision:.2f}, Recall: {epoch_val_recall:.2f}, F1: {epoch_val_f1:.2f}\\n\")"
      ],
      "metadata": {
        "id": "XXEq8B__vnpm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------------\n",
        "## 3.5 Implementaci√≥n de Early Stopping basado en rendimiento de validaci√≥n\n",
        "\n",
        "### ¬øQu√© es Early Stopping?\n",
        "\n",
        "Early stopping es una t√©cnica que detiene el entrenamiento de un modelo cuando la m√©trica de evaluaci√≥n en el conjunto de validaci√≥n deja de mejorar despu√©s de un n√∫mero determinado de √©pocas (llamado *patiencia*). Esto ayuda a prevenir el sobreajuste y a optimizar el uso de recursos computacionales.\n",
        "\n",
        "---\n",
        "\n",
        "### Funcionamiento en el c√≥digo\n",
        "\n",
        "1. **Variable `best_f1`:**  \n",
        "   Guarda el mejor valor de F1-score observado en el conjunto de validaci√≥n. Se inicializa en 0.\n",
        "\n",
        "2. **Par√°metro `patience`:**  \n",
        "   N√∫mero de √©pocas consecutivas sin mejora permitidas antes de detener el entrenamiento (en este caso, 3).\n",
        "\n",
        "3. **Durante cada √©poca de entrenamiento:**\n",
        "\n",
        "   - Se calcula el F1-score en validaci√≥n (`epoch_val_f1`).\n",
        "   - Si `epoch_val_f1` es mejor que `best_f1`:  \n",
        "     - Se actualiza `best_f1` con el nuevo valor.  \n",
        "     - Se guarda el estado actual del modelo (`best_model.pth`).  \n",
        "     - Se reinicia el contador de √©pocas sin mejora (`counter = 0`).\n",
        "   - Si no hay mejora:  \n",
        "     - Se incrementa el contador (`counter += 1`).\n",
        "\n",
        "4. **Condici√≥n de parada:**  \n",
        "   Si `counter` alcanza el valor de `patience`, el entrenamiento se detiene anticipadamente (`break`).\n",
        "\n",
        "5. **Al final:**  \n",
        "   Se carga el mejor modelo guardado para usarlo en evaluaciones o inferencia posteriores.\n",
        "\n",
        "### Beneficios\n",
        "\n",
        "- Evita sobreentrenar el modelo m√°s all√° del punto √≥ptimo.  \n",
        "- Reduce tiempo y recursos de entrenamiento.  \n",
        "- Garantiza que se utilice el modelo con mejor rendimiento en validaci√≥n.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xITbMzkEVz4o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# --- Fijamos la semilla para reproducibilidad ---\n",
        "# Esto asegura que los resultados sean iguales cada vez que se ejecuta el script\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "# --- Configuraci√≥n del dispositivo (GPU si est√° disponible) ---\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# --- Par√°metros de Early Stopping ---\n",
        "best_f1 = 0.0              # Mejor F1 observado hasta el momento\n",
        "patience = 3               # N¬∫ de √©pocas sin mejora antes de frenar\n",
        "counter = 0                # Cu√°ntas √©pocas seguidas no mejor√≥\n",
        "best_model_path = \"best_model.pth\"  # Donde se guarda el mejor modelo\n",
        "best_epoch = 0             # √âpoca donde se logr√≥ el mejor F1\n",
        "\n",
        "# --- Ciclo principal de entrenamiento ---\n",
        "for epoch in range(num_epochs):\n",
        "    start_time = time.time()\n",
        "\n",
        "    # --- Entrenamiento ---\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    train_preds = []\n",
        "    train_labels = []\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        # Pasamos datos a dispositivo\n",
        "        inputs, labels = inputs.to(device), labels.float().to(device)\n",
        "\n",
        "        # Paso de forward + backward\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs).squeeze()\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Acumulamos m√©tricas\n",
        "        train_loss += loss.item() * inputs.size(0)\n",
        "        preds = (outputs > 0.5).int()\n",
        "        train_preds.extend(preds.cpu().numpy())\n",
        "        train_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    # C√°lculo de m√©tricas de entrenamiento\n",
        "    epoch_train_loss = train_loss / len(train_loader.dataset)\n",
        "    epoch_train_precision = precision_score(train_labels, train_preds)\n",
        "    epoch_train_recall = recall_score(train_labels, train_preds)\n",
        "    epoch_train_f1 = f1_score(train_labels, train_preds)\n",
        "\n",
        "    # --- Validaci√≥n ---\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    val_preds = []\n",
        "    val_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.float().to(device)\n",
        "            outputs = model(inputs).squeeze()\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            val_loss += loss.item() * inputs.size(0)\n",
        "            preds = (outputs > 0.5).int()\n",
        "            val_preds.extend(preds.cpu().numpy())\n",
        "            val_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    # C√°lculo de m√©tricas de validaci√≥n\n",
        "    epoch_val_loss = val_loss / len(val_loader.dataset)\n",
        "    epoch_val_precision = precision_score(val_labels, val_preds)\n",
        "    epoch_val_recall = recall_score(val_labels, val_preds)\n",
        "    epoch_val_f1 = f1_score(val_labels, val_preds)\n",
        "\n",
        "    end_time = time.time()\n",
        "    elapsed = end_time - start_time\n",
        "\n",
        "    # --- Impresi√≥n de m√©tricas por √©poca ---\n",
        "    print(f\"üß† Epoch {epoch+1}/{num_epochs} - ‚è±Ô∏è Tiempo: {elapsed:.2f}s\")\n",
        "    print(f\"   üîπ Train -> Loss: {epoch_train_loss:.2f}, Precision: {epoch_train_precision:.2f}, Recall: {epoch_train_recall:.2f}, F1: {epoch_train_f1:.2f}\")\n",
        "    print(f\"   üî∏ Valid -> Loss: {epoch_val_loss:.2f}, Precision: {epoch_val_precision:.2f}, Recall: {epoch_val_recall:.2f}, F1: {epoch_val_f1:.2f}\")\n",
        "\n",
        "    # --- L√≥gica de Early Stopping ---\n",
        "    if epoch_val_f1 > best_f1:\n",
        "        best_f1 = epoch_val_f1\n",
        "        best_epoch = epoch + 1\n",
        "        counter = 0\n",
        "        torch.save(model.state_dict(), best_model_path)\n",
        "        print(f\"‚úÖ Mejor F1 en validaci√≥n: {best_f1:.2f} ‚Üí Modelo guardado.\\n\")\n",
        "    else:\n",
        "        counter += 1\n",
        "        print(f\"‚è∏Ô∏è Sin mejora en F1 ({counter}/{patience})\\n\")\n",
        "        if counter >= patience:\n",
        "            print(\"‚õî Early stopping activado.\")\n",
        "            break\n",
        "\n",
        "# --- Restaurar el mejor modelo antes de evaluar o usar ---\n",
        "model.load_state_dict(torch.load(best_model_path))\n",
        "print(f\"‚úÖ Modelo restaurado desde la epoch {best_epoch} con mejor F1: {best_f1:.2f}\")"
      ],
      "metadata": {
        "id": "llblUD2SWAgz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusi√≥n\n",
        "El modelo muestra una mejora consistente en las m√©tricas de validaci√≥n durante las primeras √©pocas, especialmente en F1-score, que alcanza un m√°ximo de 0.89. El entrenamiento logra mantener una buena precisi√≥n y recall, con p√©rdidas bajas tanto en entrenamiento como en validaci√≥n.\n",
        "\n",
        "Se observa que el early stopping funcion√≥ correctamente, ya que el entrenamiento se detuvo tras detectar varias √©pocas sin mejora significativa en el F1 de validaci√≥n, evitando as√≠ el sobreajuste. Adem√°s, el mejor modelo fue guardado y restaurado exitosamente para su uso posterior.\n",
        "\n",
        "En resumen, el modelo entrenado es robusto y el procedimiento de early stopping ayuda a optimizar el rendimiento y el tiempo de entrenamiento."
      ],
      "metadata": {
        "id": "4YLhwC9XDfGN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Referencias\n",
        "\n",
        "- **Material de clases**  \n",
        "  Base para la estructura del proyecto, manejo de datasets y entrenamiento con PyTorch.\n",
        "\n",
        "- **Prompts utilizados con GPT para mejorar el c√≥digo y obtener sugerencias:**\n",
        "\n",
        "  - *Descarga y descompresi√≥n segura y eficiente:*  \n",
        "    \"Necesito un script en Python que descargue un archivo ZIP desde una URL y lo descomprima, pero que primero verifique si el archivo ya est√° descargado y la carpeta ya est√° descomprimida para no repetir el proceso y no ralentizar la ejecuci√≥n. Que sea simple y con mensajes claros de estado.\"\n",
        "\n",
        "  - *Dataset personalizado en PyTorch para im√°genes de gatos y perros con transformaciones b√°sicas:*  \n",
        "    \"¬øPod√©s mostrarme c√≥mo implementar un Dataset personalizado con PyTorch para un conjunto de im√°genes de gatos y perros, y c√≥mo usarlo con un DataLoader que incluya transformaciones como resize y conversi√≥n a tensor?\"\n",
        "\n",
        "  - *Transformaciones recomendadas para dataset de im√°genes en PyTorch:*  \n",
        "    \"Estoy trabajando con el dataset de gatos y perros. ¬øQu√© transformaciones deber√≠a aplicar con PyTorch (resize, normalizaci√≥n y data augmentation) para usar en un DataLoader personalizado?\"\n",
        "\n",
        "  - *Control de aleatoriedad para reproducibilidad:*  \n",
        "    \"¬øC√≥mo aplicar una semilla fija para random_split en PyTorch?\"\n",
        "\n",
        "  - *Divisi√≥n estratificada del dataset para mantener proporci√≥n de clases:*  \n",
        "    \"¬øCu√°l es la mejor manera de mantener la proporci√≥n de clases al dividir un dataset para entrenamiento y validaci√≥n?\"\n",
        "\n",
        "  - *Detecci√≥n y filtrado de im√°genes corruptas en datasets de im√°genes:*  \n",
        "    \"¬øC√≥mo detectar y filtrar im√°genes corruptas en un dataset de im√°genes en PyTorch?\"  \n",
        "    \"¬øC√≥mo validar que las im√°genes de un dataset est√©n en formato RGB y no corruptas antes de usarlas?\"\n",
        "\n",
        "  - *Buenas pr√°cticas para limpieza de datasets de im√°genes:*  \n",
        "    \"¬øQu√© criterios puedo usar para limpiar un dataset de im√°genes antes del entrenamiento?\"\n",
        "\n",
        "  - *Configuraci√≥n de hiperpar√°metros para entrenamiento en PyTorch:*  \n",
        "    \"¬øC√≥mo configuro correctamente el learning rate, batch size y n√∫mero de √©pocas para entrenar un modelo en PyTorch?\"\n",
        "\n",
        "  - *Funci√≥n de p√©rdida y optimizador para clasificaci√≥n binaria:*  \n",
        "    \"¬øCu√°l es la funci√≥n de p√©rdida m√°s adecuada para un problema de clasificaci√≥n binaria?\"\n",
        "\n",
        "  - *Implementaci√≥n de early stopping en PyTorch para control de sobreajuste:*  \n",
        "    \"¬øC√≥mo implemento early stopping en PyTorch para detener el entrenamiento cuando la m√©trica de validaci√≥n deja de mejorar?\"\n"
      ],
      "metadata": {
        "id": "-mED4bzyNSyh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "_____________\n",
        "______________\n",
        "_____________"
      ],
      "metadata": {
        "id": "wiYwcI-VY6KH"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}